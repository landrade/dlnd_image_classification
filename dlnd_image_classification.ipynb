{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "# Use Floyd's cifar-10 dataset if present\n",
    "floyd_cifar10_location = '/input/cifar-10/python.tar.gz'\n",
    "if isfile(floyd_cifar10_location):\n",
    "    tar_gz_path = floyd_cifar10_location\n",
    "else:\n",
    "    tar_gz_path = 'cifar-10-python.tar.gz'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(tar_gz_path):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            tar_gz_path,\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open(tar_gz_path) as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1142737400>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return (x-x.min())/(x.max()-x.min())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return np.eye(10)[x]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, (None, *image_shape), name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, [None,n_classes], name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32,None, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    shape = x_tensor.get_shape().as_list()\n",
    "    size = (conv_ksize[0], conv_ksize[1], shape[3], conv_num_outputs)\n",
    "    W = tf.Variable(tf.truncated_normal(size, 0, (1/ sqrt(shape[1]*shape[2]*shape[3]))))\n",
    "    B = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    tensor = tf.nn.conv2d(x_tensor, W, strides=[1, conv_strides[0], conv_strides[1], 1], padding='SAME')\n",
    "    tensor = tf.nn.bias_add(tensor, B)\n",
    "    tensor = tf.nn.relu(tensor)\n",
    "    tensor = tf.nn.max_pool(tensor, ksize=[1, pool_ksize[0], pool_ksize[1], 1], strides=[1, pool_strides[0], pool_strides[1], 1], padding='SAME')\n",
    "    return tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.reshape(x_tensor, [-1, x_tensor.shape[1].value * x_tensor.shape[2].value* x_tensor.shape[3].value])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight= tf.Variable(tf.truncated_normal([x_tensor.shape[1].value, num_outputs], mean=0.0, stddev=0.1))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    \n",
    "    return tf.nn.relu(tf.nn.bias_add(tf.matmul(x_tensor, weight), bias))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weight= tf.Variable(tf.truncated_normal([x_tensor.shape[1].value, num_outputs], mean=0.0, stddev=0.01))\n",
    "    bias = tf.Variable(tf.zeros(num_outputs))\n",
    "    return tf.nn.bias_add(tf.matmul(x_tensor, weight), bias)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv1 = conv2d_maxpool(x, 20, [5,5], [1,1], [2,2], [2,2])\n",
    "    conv2 = conv2d_maxpool(conv1, 50, conv_ksize=[3,3], conv_strides=[1,1], pool_ksize=[2,2], pool_strides=[2,2])\n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob)\n",
    "    \n",
    "    conv_out = conv2\n",
    "    \n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    fl0 = flatten(conv_out)\n",
    "    \n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fl1 = fully_conn(fl0, 100)\n",
    "    fl1 = tf.nn.dropout(fl1, keep_prob)\n",
    "    \n",
    "    fl2 = fully_conn(fl1, 50)\n",
    "    fl2 = tf.nn.dropout(fl2, keep_prob+0.2)\n",
    "    \n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out = output(fl2,10)\n",
    "    \n",
    "    \n",
    "    # TODO: return output\n",
    "    return out\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer,feed_dict={x:feature_batch, y:label_batch, keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    loss = session.run(cost, feed_dict={x:feature_batch, y: label_batch, keep_prob:1.0 })\n",
    "    valid_acc =session.run(accuracy, feed_dict={x:valid_features, y: valid_labels, keep_prob:1.0})\n",
    "    print('cost: {}  accuracy: {}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  cost: 2.231597423553467  accuracy: 0.19840000569820404\n",
      "Epoch  2, CIFAR-10 Batch 1:  cost: 2.2107367515563965  accuracy: 0.2637999951839447\n",
      "Epoch  3, CIFAR-10 Batch 1:  cost: 2.190366506576538  accuracy: 0.2825999855995178\n",
      "Epoch  4, CIFAR-10 Batch 1:  cost: 2.083747625350952  accuracy: 0.34619995951652527\n",
      "Epoch  5, CIFAR-10 Batch 1:  cost: 2.036180257797241  accuracy: 0.36039999127388\n",
      "Epoch  6, CIFAR-10 Batch 1:  cost: 1.9624292850494385  accuracy: 0.38540002703666687\n",
      "Epoch  7, CIFAR-10 Batch 1:  cost: 1.8592631816864014  accuracy: 0.3951999545097351\n",
      "Epoch  8, CIFAR-10 Batch 1:  cost: 1.8503713607788086  accuracy: 0.4131999611854553\n",
      "Epoch  9, CIFAR-10 Batch 1:  cost: 1.8234999179840088  accuracy: 0.4261999726295471\n",
      "Epoch 10, CIFAR-10 Batch 1:  cost: 1.7098644971847534  accuracy: 0.42959997057914734\n",
      "Epoch 11, CIFAR-10 Batch 1:  cost: 1.7015666961669922  accuracy: 0.4472000002861023\n",
      "Epoch 12, CIFAR-10 Batch 1:  cost: 1.6282379627227783  accuracy: 0.45260000228881836\n",
      "Epoch 13, CIFAR-10 Batch 1:  cost: 1.6486237049102783  accuracy: 0.45139995217323303\n",
      "Epoch 14, CIFAR-10 Batch 1:  cost: 1.6000173091888428  accuracy: 0.4580000042915344\n",
      "Epoch 15, CIFAR-10 Batch 1:  cost: 1.528435468673706  accuracy: 0.4749999940395355\n",
      "Epoch 16, CIFAR-10 Batch 1:  cost: 1.50962495803833  accuracy: 0.47199997305870056\n",
      "Epoch 17, CIFAR-10 Batch 1:  cost: 1.51210618019104  accuracy: 0.4691999554634094\n",
      "Epoch 18, CIFAR-10 Batch 1:  cost: 1.416234016418457  accuracy: 0.47339996695518494\n",
      "Epoch 19, CIFAR-10 Batch 1:  cost: 1.5248641967773438  accuracy: 0.4797999858856201\n",
      "Epoch 20, CIFAR-10 Batch 1:  cost: 1.426177740097046  accuracy: 0.48179998993873596\n",
      "Epoch 21, CIFAR-10 Batch 1:  cost: 1.3235218524932861  accuracy: 0.48719993233680725\n",
      "Epoch 22, CIFAR-10 Batch 1:  cost: 1.361550211906433  accuracy: 0.47380000352859497\n",
      "Epoch 23, CIFAR-10 Batch 1:  cost: 1.3588347434997559  accuracy: 0.4893999695777893\n",
      "Epoch 24, CIFAR-10 Batch 1:  cost: 1.3103249073028564  accuracy: 0.4949999451637268\n",
      "Epoch 25, CIFAR-10 Batch 1:  cost: 1.301250696182251  accuracy: 0.5021999478340149\n",
      "Epoch 26, CIFAR-10 Batch 1:  cost: 1.3234885931015015  accuracy: 0.5033999681472778\n",
      "Epoch 27, CIFAR-10 Batch 1:  cost: 1.2237080335617065  accuracy: 0.5079999566078186\n",
      "Epoch 28, CIFAR-10 Batch 1:  cost: 1.2509640455245972  accuracy: 0.5009999871253967\n",
      "Epoch 29, CIFAR-10 Batch 1:  cost: 1.2265434265136719  accuracy: 0.5107999444007874\n",
      "Epoch 30, CIFAR-10 Batch 1:  cost: 1.2101763486862183  accuracy: 0.5203999280929565\n",
      "Epoch 31, CIFAR-10 Batch 1:  cost: 1.1659245491027832  accuracy: 0.5165998935699463\n",
      "Epoch 32, CIFAR-10 Batch 1:  cost: 1.1671884059906006  accuracy: 0.5185999870300293\n",
      "Epoch 33, CIFAR-10 Batch 1:  cost: 1.1145615577697754  accuracy: 0.5241999626159668\n",
      "Epoch 34, CIFAR-10 Batch 1:  cost: 1.115221619606018  accuracy: 0.5227999091148376\n",
      "Epoch 35, CIFAR-10 Batch 1:  cost: 1.1125352382659912  accuracy: 0.5245999693870544\n",
      "Epoch 36, CIFAR-10 Batch 1:  cost: 1.0935026407241821  accuracy: 0.5151999592781067\n",
      "Epoch 37, CIFAR-10 Batch 1:  cost: 1.0750640630722046  accuracy: 0.5181999206542969\n",
      "Epoch 38, CIFAR-10 Batch 1:  cost: 1.1227667331695557  accuracy: 0.5101999044418335\n",
      "Epoch 39, CIFAR-10 Batch 1:  cost: 1.063636302947998  accuracy: 0.5277999639511108\n",
      "Epoch 40, CIFAR-10 Batch 1:  cost: 1.0239648818969727  accuracy: 0.5265999436378479\n",
      "Epoch 41, CIFAR-10 Batch 1:  cost: 0.9946589469909668  accuracy: 0.5321999192237854\n",
      "Epoch 42, CIFAR-10 Batch 1:  cost: 0.984756588935852  accuracy: 0.5283998847007751\n",
      "Epoch 43, CIFAR-10 Batch 1:  cost: 0.9540690183639526  accuracy: 0.5241999626159668\n",
      "Epoch 44, CIFAR-10 Batch 1:  cost: 0.964361310005188  accuracy: 0.5231999158859253\n",
      "Epoch 45, CIFAR-10 Batch 1:  cost: 0.9448233842849731  accuracy: 0.5405999422073364\n",
      "Epoch 46, CIFAR-10 Batch 1:  cost: 0.9320048093795776  accuracy: 0.5437999367713928\n",
      "Epoch 47, CIFAR-10 Batch 1:  cost: 0.9451249837875366  accuracy: 0.5347999334335327\n",
      "Epoch 48, CIFAR-10 Batch 1:  cost: 0.86942058801651  accuracy: 0.5461999177932739\n",
      "Epoch 49, CIFAR-10 Batch 1:  cost: 0.862623929977417  accuracy: 0.5499998927116394\n",
      "Epoch 50, CIFAR-10 Batch 1:  cost: 0.8727645874023438  accuracy: 0.5401999354362488\n",
      "Epoch 51, CIFAR-10 Batch 1:  cost: 0.8577927350997925  accuracy: 0.5553999543190002\n",
      "Epoch 52, CIFAR-10 Batch 1:  cost: 0.8251951932907104  accuracy: 0.555199921131134\n",
      "Epoch 53, CIFAR-10 Batch 1:  cost: 0.8560818433761597  accuracy: 0.5463999509811401\n",
      "Epoch 54, CIFAR-10 Batch 1:  cost: 0.7900370359420776  accuracy: 0.5621999502182007\n",
      "Epoch 55, CIFAR-10 Batch 1:  cost: 0.7872939109802246  accuracy: 0.5625998973846436\n",
      "Epoch 56, CIFAR-10 Batch 1:  cost: 0.8091259002685547  accuracy: 0.5615999102592468\n",
      "Epoch 57, CIFAR-10 Batch 1:  cost: 0.7913995981216431  accuracy: 0.561199963092804\n",
      "Epoch 58, CIFAR-10 Batch 1:  cost: 0.7902736663818359  accuracy: 0.5625998973846436\n",
      "Epoch 59, CIFAR-10 Batch 1:  cost: 0.7554190158843994  accuracy: 0.5631999373435974\n",
      "Epoch 60, CIFAR-10 Batch 1:  cost: 0.7644822001457214  accuracy: 0.5619999170303345\n",
      "Epoch 61, CIFAR-10 Batch 1:  cost: 0.726452112197876  accuracy: 0.5751999020576477\n",
      "Epoch 62, CIFAR-10 Batch 1:  cost: 0.7255934476852417  accuracy: 0.5655999183654785\n",
      "Epoch 63, CIFAR-10 Batch 1:  cost: 0.7163260579109192  accuracy: 0.5717998743057251\n",
      "Epoch 64, CIFAR-10 Batch 1:  cost: 0.7247798442840576  accuracy: 0.5709998607635498\n",
      "Epoch 65, CIFAR-10 Batch 1:  cost: 0.7085899114608765  accuracy: 0.5741999745368958\n",
      "Epoch 66, CIFAR-10 Batch 1:  cost: 0.6715614199638367  accuracy: 0.5761998891830444\n",
      "Epoch 67, CIFAR-10 Batch 1:  cost: 0.6669738292694092  accuracy: 0.5727999210357666\n",
      "Epoch 68, CIFAR-10 Batch 1:  cost: 0.6636948585510254  accuracy: 0.5681999325752258\n",
      "Epoch 69, CIFAR-10 Batch 1:  cost: 0.6278833746910095  accuracy: 0.5871999859809875\n",
      "Epoch 70, CIFAR-10 Batch 1:  cost: 0.6655145287513733  accuracy: 0.5671999454498291\n",
      "Epoch 71, CIFAR-10 Batch 1:  cost: 0.6122816205024719  accuracy: 0.5775998830795288\n",
      "Epoch 72, CIFAR-10 Batch 1:  cost: 0.6199139356613159  accuracy: 0.5871999263763428\n",
      "Epoch 73, CIFAR-10 Batch 1:  cost: 0.6010194420814514  accuracy: 0.5821998715400696\n",
      "Epoch 74, CIFAR-10 Batch 1:  cost: 0.5790889859199524  accuracy: 0.5685999393463135\n",
      "Epoch 75, CIFAR-10 Batch 1:  cost: 0.5899062752723694  accuracy: 0.5839999318122864\n",
      "Epoch 76, CIFAR-10 Batch 1:  cost: 0.5903230905532837  accuracy: 0.5807998776435852\n",
      "Epoch 77, CIFAR-10 Batch 1:  cost: 0.591974675655365  accuracy: 0.5869999527931213\n",
      "Epoch 78, CIFAR-10 Batch 1:  cost: 0.5554203391075134  accuracy: 0.5849999189376831\n",
      "Epoch 79, CIFAR-10 Batch 1:  cost: 0.5643033385276794  accuracy: 0.5813999176025391\n",
      "Epoch 80, CIFAR-10 Batch 1:  cost: 0.5800198912620544  accuracy: 0.5733999013900757\n",
      "Epoch 81, CIFAR-10 Batch 1:  cost: 0.5593591332435608  accuracy: 0.5895999670028687\n",
      "Epoch 82, CIFAR-10 Batch 1:  cost: 0.5292356014251709  accuracy: 0.5847999453544617\n",
      "Epoch 83, CIFAR-10 Batch 1:  cost: 0.5215239524841309  accuracy: 0.5867999196052551\n",
      "Epoch 84, CIFAR-10 Batch 1:  cost: 0.5279545783996582  accuracy: 0.5935999751091003\n",
      "Epoch 85, CIFAR-10 Batch 1:  cost: 0.5173993706703186  accuracy: 0.5927999019622803\n",
      "Epoch 86, CIFAR-10 Batch 1:  cost: 0.5184982419013977  accuracy: 0.5977998971939087\n",
      "Epoch 87, CIFAR-10 Batch 1:  cost: 0.5052600502967834  accuracy: 0.5963999629020691\n",
      "Epoch 88, CIFAR-10 Batch 1:  cost: 0.4947493076324463  accuracy: 0.584399938583374\n",
      "Epoch 89, CIFAR-10 Batch 1:  cost: 0.4808087646961212  accuracy: 0.595599889755249\n",
      "Epoch 90, CIFAR-10 Batch 1:  cost: 0.49776679277420044  accuracy: 0.5953999161720276\n",
      "Epoch 91, CIFAR-10 Batch 1:  cost: 0.48216813802719116  accuracy: 0.5977999567985535\n",
      "Epoch 92, CIFAR-10 Batch 1:  cost: 0.4891985058784485  accuracy: 0.5931998491287231\n",
      "Epoch 93, CIFAR-10 Batch 1:  cost: 0.4704414904117584  accuracy: 0.5831999182701111\n",
      "Epoch 94, CIFAR-10 Batch 1:  cost: 0.4551391303539276  accuracy: 0.5945999026298523\n",
      "Epoch 95, CIFAR-10 Batch 1:  cost: 0.47818583250045776  accuracy: 0.6023998856544495\n",
      "Epoch 96, CIFAR-10 Batch 1:  cost: 0.4579312801361084  accuracy: 0.5915999412536621\n",
      "Epoch 97, CIFAR-10 Batch 1:  cost: 0.4663427472114563  accuracy: 0.5941998958587646\n",
      "Epoch 98, CIFAR-10 Batch 1:  cost: 0.47419339418411255  accuracy: 0.5981999039649963\n",
      "Epoch 99, CIFAR-10 Batch 1:  cost: 0.4505620300769806  accuracy: 0.5935999155044556\n",
      "Epoch 100, CIFAR-10 Batch 1:  cost: 0.4201992154121399  accuracy: 0.597399890422821\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  cost: 2.2457945346832275  accuracy: 0.16599999368190765\n",
      "Epoch  1, CIFAR-10 Batch 2:  cost: 2.0626144409179688  accuracy: 0.2818000018596649\n",
      "Epoch  1, CIFAR-10 Batch 3:  cost: 1.807671070098877  accuracy: 0.26579999923706055\n",
      "Epoch  1, CIFAR-10 Batch 4:  cost: 1.7551674842834473  accuracy: 0.32259997725486755\n",
      "Epoch  1, CIFAR-10 Batch 5:  cost: 1.8569859266281128  accuracy: 0.3612000048160553\n",
      "Epoch  2, CIFAR-10 Batch 1:  cost: 1.992284893989563  accuracy: 0.3887999951839447\n",
      "Epoch  2, CIFAR-10 Batch 2:  cost: 1.842621922492981  accuracy: 0.40519994497299194\n",
      "Epoch  2, CIFAR-10 Batch 3:  cost: 1.4393196105957031  accuracy: 0.4065999686717987\n",
      "Epoch  2, CIFAR-10 Batch 4:  cost: 1.557274341583252  accuracy: 0.4349999725818634\n",
      "Epoch  2, CIFAR-10 Batch 5:  cost: 1.7007018327713013  accuracy: 0.43999993801116943\n",
      "Epoch  3, CIFAR-10 Batch 1:  cost: 1.7768754959106445  accuracy: 0.4577999711036682\n",
      "Epoch  3, CIFAR-10 Batch 2:  cost: 1.6110060214996338  accuracy: 0.46359995007514954\n",
      "Epoch  3, CIFAR-10 Batch 3:  cost: 1.240493655204773  accuracy: 0.4607999920845032\n",
      "Epoch  3, CIFAR-10 Batch 4:  cost: 1.477034330368042  accuracy: 0.4787999391555786\n",
      "Epoch  3, CIFAR-10 Batch 5:  cost: 1.6384835243225098  accuracy: 0.4615999758243561\n",
      "Epoch  4, CIFAR-10 Batch 1:  cost: 1.6081255674362183  accuracy: 0.47819995880126953\n",
      "Epoch  4, CIFAR-10 Batch 2:  cost: 1.4779292345046997  accuracy: 0.4769999384880066\n",
      "Epoch  4, CIFAR-10 Batch 3:  cost: 1.138390302658081  accuracy: 0.48339998722076416\n",
      "Epoch  4, CIFAR-10 Batch 4:  cost: 1.4311623573303223  accuracy: 0.4957999587059021\n",
      "Epoch  4, CIFAR-10 Batch 5:  cost: 1.5541768074035645  accuracy: 0.4971999526023865\n",
      "Epoch  5, CIFAR-10 Batch 1:  cost: 1.542224645614624  accuracy: 0.5061998963356018\n",
      "Epoch  5, CIFAR-10 Batch 2:  cost: 1.4397941827774048  accuracy: 0.4981999397277832\n",
      "Epoch  5, CIFAR-10 Batch 3:  cost: 1.0921244621276855  accuracy: 0.4989999532699585\n",
      "Epoch  5, CIFAR-10 Batch 4:  cost: 1.4252028465270996  accuracy: 0.4989999532699585\n",
      "Epoch  5, CIFAR-10 Batch 5:  cost: 1.5370831489562988  accuracy: 0.5005999803543091\n",
      "Epoch  6, CIFAR-10 Batch 1:  cost: 1.4653246402740479  accuracy: 0.517799973487854\n",
      "Epoch  6, CIFAR-10 Batch 2:  cost: 1.2995015382766724  accuracy: 0.5197999477386475\n",
      "Epoch  6, CIFAR-10 Batch 3:  cost: 1.0832422971725464  accuracy: 0.5039999485015869\n",
      "Epoch  6, CIFAR-10 Batch 4:  cost: 1.2481920719146729  accuracy: 0.5269999504089355\n",
      "Epoch  6, CIFAR-10 Batch 5:  cost: 1.4192994832992554  accuracy: 0.5239999294281006\n",
      "Epoch  7, CIFAR-10 Batch 1:  cost: 1.4664934873580933  accuracy: 0.5349999666213989\n",
      "Epoch  7, CIFAR-10 Batch 2:  cost: 1.2641401290893555  accuracy: 0.5267999172210693\n",
      "Epoch  7, CIFAR-10 Batch 3:  cost: 1.0062789916992188  accuracy: 0.5215999484062195\n",
      "Epoch  7, CIFAR-10 Batch 4:  cost: 1.2127920389175415  accuracy: 0.5415999293327332\n",
      "Epoch  7, CIFAR-10 Batch 5:  cost: 1.3663712739944458  accuracy: 0.5277999639511108\n",
      "Epoch  8, CIFAR-10 Batch 1:  cost: 1.3809669017791748  accuracy: 0.5525999069213867\n",
      "Epoch  8, CIFAR-10 Batch 2:  cost: 1.1960794925689697  accuracy: 0.5501999258995056\n",
      "Epoch  8, CIFAR-10 Batch 3:  cost: 1.0048500299453735  accuracy: 0.5437999367713928\n",
      "Epoch  8, CIFAR-10 Batch 4:  cost: 1.172358512878418  accuracy: 0.5549999475479126\n",
      "Epoch  8, CIFAR-10 Batch 5:  cost: 1.2817150354385376  accuracy: 0.553399920463562\n",
      "Epoch  9, CIFAR-10 Batch 1:  cost: 1.3117340803146362  accuracy: 0.5547999143600464\n",
      "Epoch  9, CIFAR-10 Batch 2:  cost: 1.1290380954742432  accuracy: 0.5547999739646912\n",
      "Epoch  9, CIFAR-10 Batch 3:  cost: 0.9849210381507874  accuracy: 0.5561999082565308\n",
      "Epoch  9, CIFAR-10 Batch 4:  cost: 1.1105434894561768  accuracy: 0.568399965763092\n",
      "Epoch  9, CIFAR-10 Batch 5:  cost: 1.2383617162704468  accuracy: 0.5655999183654785\n",
      "Epoch 10, CIFAR-10 Batch 1:  cost: 1.2894501686096191  accuracy: 0.5701999664306641\n",
      "Epoch 10, CIFAR-10 Batch 2:  cost: 1.1076297760009766  accuracy: 0.5607998967170715\n",
      "Epoch 10, CIFAR-10 Batch 3:  cost: 0.9036020040512085  accuracy: 0.5683999061584473\n",
      "Epoch 10, CIFAR-10 Batch 4:  cost: 1.0566165447235107  accuracy: 0.5739999413490295\n",
      "Epoch 10, CIFAR-10 Batch 5:  cost: 1.1677124500274658  accuracy: 0.5751999616622925\n",
      "Epoch 11, CIFAR-10 Batch 1:  cost: 1.2301872968673706  accuracy: 0.58079993724823\n",
      "Epoch 11, CIFAR-10 Batch 2:  cost: 1.013649821281433  accuracy: 0.5771998763084412\n",
      "Epoch 11, CIFAR-10 Batch 3:  cost: 0.8667186498641968  accuracy: 0.5755999088287354\n",
      "Epoch 11, CIFAR-10 Batch 4:  cost: 1.0103179216384888  accuracy: 0.5907999873161316\n",
      "Epoch 11, CIFAR-10 Batch 5:  cost: 1.1169722080230713  accuracy: 0.5845998525619507\n",
      "Epoch 12, CIFAR-10 Batch 1:  cost: 1.1552746295928955  accuracy: 0.5941999554634094\n",
      "Epoch 12, CIFAR-10 Batch 2:  cost: 0.9965904951095581  accuracy: 0.5863999724388123\n",
      "Epoch 12, CIFAR-10 Batch 3:  cost: 0.8414152264595032  accuracy: 0.5933999419212341\n",
      "Epoch 12, CIFAR-10 Batch 4:  cost: 1.0291674137115479  accuracy: 0.5921999216079712\n",
      "Epoch 12, CIFAR-10 Batch 5:  cost: 1.0903046131134033  accuracy: 0.5993998646736145\n",
      "Epoch 13, CIFAR-10 Batch 1:  cost: 1.135954737663269  accuracy: 0.5971999168395996\n",
      "Epoch 13, CIFAR-10 Batch 2:  cost: 0.9418503046035767  accuracy: 0.5931999087333679\n",
      "Epoch 13, CIFAR-10 Batch 3:  cost: 0.8424960970878601  accuracy: 0.5913999676704407\n",
      "Epoch 13, CIFAR-10 Batch 4:  cost: 0.9865822792053223  accuracy: 0.6031998991966248\n",
      "Epoch 13, CIFAR-10 Batch 5:  cost: 0.997858464717865  accuracy: 0.6045998930931091\n",
      "Epoch 14, CIFAR-10 Batch 1:  cost: 1.0820021629333496  accuracy: 0.6055998802185059\n",
      "Epoch 14, CIFAR-10 Batch 2:  cost: 0.9732010960578918  accuracy: 0.603399932384491\n",
      "Epoch 14, CIFAR-10 Batch 3:  cost: 0.7746144533157349  accuracy: 0.614799976348877\n",
      "Epoch 14, CIFAR-10 Batch 4:  cost: 0.9335899353027344  accuracy: 0.6129998564720154\n",
      "Epoch 14, CIFAR-10 Batch 5:  cost: 1.004145860671997  accuracy: 0.6001999378204346\n",
      "Epoch 15, CIFAR-10 Batch 1:  cost: 1.0452584028244019  accuracy: 0.6127999424934387\n",
      "Epoch 15, CIFAR-10 Batch 2:  cost: 0.9440367221832275  accuracy: 0.6069998741149902\n",
      "Epoch 15, CIFAR-10 Batch 3:  cost: 0.7709468603134155  accuracy: 0.6123999357223511\n",
      "Epoch 15, CIFAR-10 Batch 4:  cost: 0.9210984706878662  accuracy: 0.6087998747825623\n",
      "Epoch 15, CIFAR-10 Batch 5:  cost: 1.017339825630188  accuracy: 0.6085999011993408\n",
      "Epoch 16, CIFAR-10 Batch 1:  cost: 0.9881192445755005  accuracy: 0.6239999532699585\n",
      "Epoch 16, CIFAR-10 Batch 2:  cost: 0.8981592059135437  accuracy: 0.6129999160766602\n",
      "Epoch 16, CIFAR-10 Batch 3:  cost: 0.769059419631958  accuracy: 0.6125999093055725\n",
      "Epoch 16, CIFAR-10 Batch 4:  cost: 0.8721596002578735  accuracy: 0.6275999546051025\n",
      "Epoch 16, CIFAR-10 Batch 5:  cost: 0.9478088617324829  accuracy: 0.6279998421669006\n",
      "Epoch 17, CIFAR-10 Batch 1:  cost: 1.007070541381836  accuracy: 0.626599907875061\n",
      "Epoch 17, CIFAR-10 Batch 2:  cost: 0.8628305792808533  accuracy: 0.6201999187469482\n",
      "Epoch 17, CIFAR-10 Batch 3:  cost: 0.7382961511611938  accuracy: 0.6245999336242676\n",
      "Epoch 17, CIFAR-10 Batch 4:  cost: 0.8681846261024475  accuracy: 0.6171998977661133\n",
      "Epoch 17, CIFAR-10 Batch 5:  cost: 0.8990747332572937  accuracy: 0.626599907875061\n",
      "Epoch 18, CIFAR-10 Batch 1:  cost: 0.8822497129440308  accuracy: 0.6331998705863953\n",
      "Epoch 18, CIFAR-10 Batch 2:  cost: 0.881851315498352  accuracy: 0.6357998847961426\n",
      "Epoch 18, CIFAR-10 Batch 3:  cost: 0.6756216883659363  accuracy: 0.6399998664855957\n",
      "Epoch 18, CIFAR-10 Batch 4:  cost: 0.8124587535858154  accuracy: 0.6413998603820801\n",
      "Epoch 18, CIFAR-10 Batch 5:  cost: 0.8182375431060791  accuracy: 0.6313998699188232\n",
      "Epoch 19, CIFAR-10 Batch 1:  cost: 0.9704770445823669  accuracy: 0.6329998970031738\n",
      "Epoch 19, CIFAR-10 Batch 2:  cost: 0.8385305404663086  accuracy: 0.6431999206542969\n",
      "Epoch 19, CIFAR-10 Batch 3:  cost: 0.6352170705795288  accuracy: 0.6437998414039612\n",
      "Epoch 19, CIFAR-10 Batch 4:  cost: 0.8486833572387695  accuracy: 0.6441999673843384\n",
      "Epoch 19, CIFAR-10 Batch 5:  cost: 0.8441634178161621  accuracy: 0.6469998955726624\n",
      "Epoch 20, CIFAR-10 Batch 1:  cost: 0.9427915811538696  accuracy: 0.644399881362915\n",
      "Epoch 20, CIFAR-10 Batch 2:  cost: 0.7745019793510437  accuracy: 0.6333999037742615\n",
      "Epoch 20, CIFAR-10 Batch 3:  cost: 0.691311240196228  accuracy: 0.6423999071121216\n",
      "Epoch 20, CIFAR-10 Batch 4:  cost: 0.7770861387252808  accuracy: 0.6483998894691467\n",
      "Epoch 20, CIFAR-10 Batch 5:  cost: 0.7987934350967407  accuracy: 0.6483998894691467\n",
      "Epoch 21, CIFAR-10 Batch 1:  cost: 0.8600484728813171  accuracy: 0.6505998969078064\n",
      "Epoch 21, CIFAR-10 Batch 2:  cost: 0.7871882915496826  accuracy: 0.6545998454093933\n",
      "Epoch 21, CIFAR-10 Batch 3:  cost: 0.6071614027023315  accuracy: 0.6467998623847961\n",
      "Epoch 21, CIFAR-10 Batch 4:  cost: 0.7694414258003235  accuracy: 0.654999852180481\n",
      "Epoch 21, CIFAR-10 Batch 5:  cost: 0.8099629282951355  accuracy: 0.6471999287605286\n",
      "Epoch 22, CIFAR-10 Batch 1:  cost: 0.8799927234649658  accuracy: 0.6489999294281006\n",
      "Epoch 22, CIFAR-10 Batch 2:  cost: 0.758376955986023  accuracy: 0.6549999117851257\n",
      "Epoch 22, CIFAR-10 Batch 3:  cost: 0.5890371799468994  accuracy: 0.6497998833656311\n",
      "Epoch 22, CIFAR-10 Batch 4:  cost: 0.74897700548172  accuracy: 0.6563998460769653\n",
      "Epoch 22, CIFAR-10 Batch 5:  cost: 0.7715266346931458  accuracy: 0.64739990234375\n",
      "Epoch 23, CIFAR-10 Batch 1:  cost: 0.8536548614501953  accuracy: 0.6525999307632446\n",
      "Epoch 23, CIFAR-10 Batch 2:  cost: 0.7460029721260071  accuracy: 0.6553998589515686\n",
      "Epoch 23, CIFAR-10 Batch 3:  cost: 0.5773692727088928  accuracy: 0.654999852180481\n",
      "Epoch 23, CIFAR-10 Batch 4:  cost: 0.7240825295448303  accuracy: 0.6529998183250427\n",
      "Epoch 23, CIFAR-10 Batch 5:  cost: 0.7529346942901611  accuracy: 0.6629998683929443\n",
      "Epoch 24, CIFAR-10 Batch 1:  cost: 0.8250154256820679  accuracy: 0.6445999145507812\n",
      "Epoch 24, CIFAR-10 Batch 2:  cost: 0.705894410610199  accuracy: 0.6609999537467957\n",
      "Epoch 24, CIFAR-10 Batch 3:  cost: 0.556020200252533  accuracy: 0.6587998867034912\n",
      "Epoch 24, CIFAR-10 Batch 4:  cost: 0.7187646627426147  accuracy: 0.6569998860359192\n",
      "Epoch 24, CIFAR-10 Batch 5:  cost: 0.7542855739593506  accuracy: 0.6651999354362488\n",
      "Epoch 25, CIFAR-10 Batch 1:  cost: 0.7913020849227905  accuracy: 0.6659998893737793\n",
      "Epoch 25, CIFAR-10 Batch 2:  cost: 0.7102277874946594  accuracy: 0.6689999103546143\n",
      "Epoch 25, CIFAR-10 Batch 3:  cost: 0.6092687845230103  accuracy: 0.6563998460769653\n",
      "Epoch 25, CIFAR-10 Batch 4:  cost: 0.6854145526885986  accuracy: 0.6673998832702637\n",
      "Epoch 25, CIFAR-10 Batch 5:  cost: 0.7130077481269836  accuracy: 0.6673998832702637\n",
      "Epoch 26, CIFAR-10 Batch 1:  cost: 0.8219857215881348  accuracy: 0.66159987449646\n",
      "Epoch 26, CIFAR-10 Batch 2:  cost: 0.697236180305481  accuracy: 0.6641998291015625\n",
      "Epoch 26, CIFAR-10 Batch 3:  cost: 0.5783988833427429  accuracy: 0.6649999022483826\n",
      "Epoch 26, CIFAR-10 Batch 4:  cost: 0.6661113500595093  accuracy: 0.6777998805046082\n",
      "Epoch 26, CIFAR-10 Batch 5:  cost: 0.7133237719535828  accuracy: 0.6731998920440674\n",
      "Epoch 27, CIFAR-10 Batch 1:  cost: 0.7288762927055359  accuracy: 0.6755998730659485\n",
      "Epoch 27, CIFAR-10 Batch 2:  cost: 0.6641041040420532  accuracy: 0.6811999082565308\n",
      "Epoch 27, CIFAR-10 Batch 3:  cost: 0.5489420294761658  accuracy: 0.6675999164581299\n",
      "Epoch 27, CIFAR-10 Batch 4:  cost: 0.6846352815628052  accuracy: 0.665199875831604\n",
      "Epoch 27, CIFAR-10 Batch 5:  cost: 0.7152993083000183  accuracy: 0.6755998730659485\n",
      "Epoch 28, CIFAR-10 Batch 1:  cost: 0.7361581325531006  accuracy: 0.6767998933792114\n",
      "Epoch 28, CIFAR-10 Batch 2:  cost: 0.6856704354286194  accuracy: 0.6759998798370361\n",
      "Epoch 28, CIFAR-10 Batch 3:  cost: 0.5199756622314453  accuracy: 0.6721999049186707\n",
      "Epoch 28, CIFAR-10 Batch 4:  cost: 0.6243939995765686  accuracy: 0.6831998825073242\n",
      "Epoch 28, CIFAR-10 Batch 5:  cost: 0.7306625843048096  accuracy: 0.6821998357772827\n",
      "Epoch 29, CIFAR-10 Batch 1:  cost: 0.6768651008605957  accuracy: 0.672999918460846\n",
      "Epoch 29, CIFAR-10 Batch 2:  cost: 0.6145041584968567  accuracy: 0.6803998351097107\n",
      "Epoch 29, CIFAR-10 Batch 3:  cost: 0.5072826147079468  accuracy: 0.6757999658584595\n",
      "Epoch 29, CIFAR-10 Batch 4:  cost: 0.6680829524993896  accuracy: 0.663399875164032\n",
      "Epoch 29, CIFAR-10 Batch 5:  cost: 0.6881427764892578  accuracy: 0.679999828338623\n",
      "Epoch 30, CIFAR-10 Batch 1:  cost: 0.6965040564537048  accuracy: 0.6743998527526855\n",
      "Epoch 30, CIFAR-10 Batch 2:  cost: 0.6598066091537476  accuracy: 0.6811999082565308\n",
      "Epoch 30, CIFAR-10 Batch 3:  cost: 0.5131011009216309  accuracy: 0.6789999604225159\n",
      "Epoch 30, CIFAR-10 Batch 4:  cost: 0.6246544122695923  accuracy: 0.6857998371124268\n",
      "Epoch 30, CIFAR-10 Batch 5:  cost: 0.6981576085090637  accuracy: 0.6757999062538147\n",
      "Epoch 31, CIFAR-10 Batch 1:  cost: 0.6835793852806091  accuracy: 0.6823998689651489\n",
      "Epoch 31, CIFAR-10 Batch 2:  cost: 0.6769999861717224  accuracy: 0.6893998980522156\n",
      "Epoch 31, CIFAR-10 Batch 3:  cost: 0.5237396955490112  accuracy: 0.6813998222351074\n",
      "Epoch 31, CIFAR-10 Batch 4:  cost: 0.598100483417511  accuracy: 0.6767999529838562\n",
      "Epoch 31, CIFAR-10 Batch 5:  cost: 0.6480492353439331  accuracy: 0.6845998764038086\n",
      "Epoch 32, CIFAR-10 Batch 1:  cost: 0.6661234498023987  accuracy: 0.6881998777389526\n",
      "Epoch 32, CIFAR-10 Batch 2:  cost: 0.6874678134918213  accuracy: 0.6777999401092529\n",
      "Epoch 32, CIFAR-10 Batch 3:  cost: 0.5024082064628601  accuracy: 0.6901999115943909\n",
      "Epoch 32, CIFAR-10 Batch 4:  cost: 0.574047327041626  accuracy: 0.6917998790740967\n",
      "Epoch 32, CIFAR-10 Batch 5:  cost: 0.6786254644393921  accuracy: 0.6945998668670654\n",
      "Epoch 33, CIFAR-10 Batch 1:  cost: 0.6563788056373596  accuracy: 0.6839998364448547\n",
      "Epoch 33, CIFAR-10 Batch 2:  cost: 0.6466660499572754  accuracy: 0.6773998737335205\n",
      "Epoch 33, CIFAR-10 Batch 3:  cost: 0.46438068151474  accuracy: 0.6917998790740967\n",
      "Epoch 33, CIFAR-10 Batch 4:  cost: 0.5443361401557922  accuracy: 0.6909998655319214\n",
      "Epoch 33, CIFAR-10 Batch 5:  cost: 0.6149719953536987  accuracy: 0.682999849319458\n",
      "Epoch 34, CIFAR-10 Batch 1:  cost: 0.6965415477752686  accuracy: 0.6777998805046082\n",
      "Epoch 34, CIFAR-10 Batch 2:  cost: 0.6847589015960693  accuracy: 0.6813998818397522\n",
      "Epoch 34, CIFAR-10 Batch 3:  cost: 0.4947693943977356  accuracy: 0.6873999238014221\n",
      "Epoch 34, CIFAR-10 Batch 4:  cost: 0.5542553067207336  accuracy: 0.6899998188018799\n",
      "Epoch 34, CIFAR-10 Batch 5:  cost: 0.6506265997886658  accuracy: 0.6931998133659363\n",
      "Epoch 35, CIFAR-10 Batch 1:  cost: 0.6376423239707947  accuracy: 0.6825999021530151\n",
      "Epoch 35, CIFAR-10 Batch 2:  cost: 0.601910412311554  accuracy: 0.69159996509552\n",
      "Epoch 35, CIFAR-10 Batch 3:  cost: 0.4507732093334198  accuracy: 0.6835998296737671\n",
      "Epoch 35, CIFAR-10 Batch 4:  cost: 0.5478083491325378  accuracy: 0.6857998967170715\n",
      "Epoch 35, CIFAR-10 Batch 5:  cost: 0.6199108958244324  accuracy: 0.6889998316764832\n",
      "Epoch 36, CIFAR-10 Batch 1:  cost: 0.6195929050445557  accuracy: 0.6873998641967773\n",
      "Epoch 36, CIFAR-10 Batch 2:  cost: 0.6449271440505981  accuracy: 0.6875998973846436\n",
      "Epoch 36, CIFAR-10 Batch 3:  cost: 0.49700820446014404  accuracy: 0.6871998310089111\n",
      "Epoch 36, CIFAR-10 Batch 4:  cost: 0.5535992383956909  accuracy: 0.6921998858451843\n",
      "Epoch 36, CIFAR-10 Batch 5:  cost: 0.5851097702980042  accuracy: 0.6935998797416687\n",
      "Epoch 37, CIFAR-10 Batch 1:  cost: 0.6071743369102478  accuracy: 0.6955997943878174\n",
      "Epoch 37, CIFAR-10 Batch 2:  cost: 0.6211071610450745  accuracy: 0.6849998831748962\n",
      "Epoch 37, CIFAR-10 Batch 3:  cost: 0.4960569739341736  accuracy: 0.6829999089241028\n",
      "Epoch 37, CIFAR-10 Batch 4:  cost: 0.5310785174369812  accuracy: 0.6969997882843018\n",
      "Epoch 37, CIFAR-10 Batch 5:  cost: 0.5893509387969971  accuracy: 0.6987999081611633\n",
      "Epoch 38, CIFAR-10 Batch 1:  cost: 0.6057633757591248  accuracy: 0.689599871635437\n",
      "Epoch 38, CIFAR-10 Batch 2:  cost: 0.5461957454681396  accuracy: 0.6993998885154724\n",
      "Epoch 38, CIFAR-10 Batch 3:  cost: 0.47409769892692566  accuracy: 0.6891998648643494\n",
      "Epoch 38, CIFAR-10 Batch 4:  cost: 0.5209406018257141  accuracy: 0.6911998391151428\n",
      "Epoch 38, CIFAR-10 Batch 5:  cost: 0.5861363410949707  accuracy: 0.6849998831748962\n",
      "Epoch 39, CIFAR-10 Batch 1:  cost: 0.5730130076408386  accuracy: 0.6929998397827148\n",
      "Epoch 39, CIFAR-10 Batch 2:  cost: 0.6160890460014343  accuracy: 0.6957998275756836\n",
      "Epoch 39, CIFAR-10 Batch 3:  cost: 0.42847132682800293  accuracy: 0.6939998269081116\n",
      "Epoch 39, CIFAR-10 Batch 4:  cost: 0.5118178129196167  accuracy: 0.6951999068260193\n",
      "Epoch 39, CIFAR-10 Batch 5:  cost: 0.5802181959152222  accuracy: 0.6943998336791992\n",
      "Epoch 40, CIFAR-10 Batch 1:  cost: 0.5672914385795593  accuracy: 0.707399845123291\n",
      "Epoch 40, CIFAR-10 Batch 2:  cost: 0.566367506980896  accuracy: 0.6891998648643494\n",
      "Epoch 40, CIFAR-10 Batch 3:  cost: 0.4141460657119751  accuracy: 0.6985998749732971\n",
      "Epoch 40, CIFAR-10 Batch 4:  cost: 0.5325881838798523  accuracy: 0.6781998872756958\n",
      "Epoch 40, CIFAR-10 Batch 5:  cost: 0.6227381229400635  accuracy: 0.6941998600959778\n",
      "Epoch 41, CIFAR-10 Batch 1:  cost: 0.5729798674583435  accuracy: 0.6945998668670654\n",
      "Epoch 41, CIFAR-10 Batch 2:  cost: 0.6131904125213623  accuracy: 0.6935998797416687\n",
      "Epoch 41, CIFAR-10 Batch 3:  cost: 0.4117226302623749  accuracy: 0.7005999088287354\n",
      "Epoch 41, CIFAR-10 Batch 4:  cost: 0.5118089318275452  accuracy: 0.6913999319076538\n",
      "Epoch 41, CIFAR-10 Batch 5:  cost: 0.5488344430923462  accuracy: 0.7003998160362244\n",
      "Epoch 42, CIFAR-10 Batch 1:  cost: 0.5643824934959412  accuracy: 0.709199845790863\n",
      "Epoch 42, CIFAR-10 Batch 2:  cost: 0.6210413575172424  accuracy: 0.7011998891830444\n",
      "Epoch 42, CIFAR-10 Batch 3:  cost: 0.39792293310165405  accuracy: 0.7059998512268066\n",
      "Epoch 42, CIFAR-10 Batch 4:  cost: 0.44990265369415283  accuracy: 0.6917998790740967\n",
      "Epoch 42, CIFAR-10 Batch 5:  cost: 0.5291038751602173  accuracy: 0.696199893951416\n",
      "Epoch 43, CIFAR-10 Batch 1:  cost: 0.5806341171264648  accuracy: 0.6993998289108276\n",
      "Epoch 43, CIFAR-10 Batch 2:  cost: 0.5737005472183228  accuracy: 0.6927998661994934\n",
      "Epoch 43, CIFAR-10 Batch 3:  cost: 0.4248853325843811  accuracy: 0.6947999000549316\n",
      "Epoch 43, CIFAR-10 Batch 4:  cost: 0.5077019929885864  accuracy: 0.703799843788147\n",
      "Epoch 43, CIFAR-10 Batch 5:  cost: 0.5769401788711548  accuracy: 0.7061998844146729\n",
      "Epoch 44, CIFAR-10 Batch 1:  cost: 0.5249536633491516  accuracy: 0.6983998417854309\n",
      "Epoch 44, CIFAR-10 Batch 2:  cost: 0.5961924195289612  accuracy: 0.6869998574256897\n",
      "Epoch 44, CIFAR-10 Batch 3:  cost: 0.3811156451702118  accuracy: 0.7065998911857605\n",
      "Epoch 44, CIFAR-10 Batch 4:  cost: 0.4968465566635132  accuracy: 0.7041997909545898\n",
      "Epoch 44, CIFAR-10 Batch 5:  cost: 0.5720036029815674  accuracy: 0.7011998891830444\n",
      "Epoch 45, CIFAR-10 Batch 1:  cost: 0.5195974111557007  accuracy: 0.7021998167037964\n",
      "Epoch 45, CIFAR-10 Batch 2:  cost: 0.5846892595291138  accuracy: 0.7013998031616211\n",
      "Epoch 45, CIFAR-10 Batch 3:  cost: 0.39693060517311096  accuracy: 0.7011998891830444\n",
      "Epoch 45, CIFAR-10 Batch 4:  cost: 0.443600594997406  accuracy: 0.7045998573303223\n",
      "Epoch 45, CIFAR-10 Batch 5:  cost: 0.5684119462966919  accuracy: 0.6987998485565186\n",
      "Epoch 46, CIFAR-10 Batch 1:  cost: 0.5568195581436157  accuracy: 0.7035998702049255\n",
      "Epoch 46, CIFAR-10 Batch 2:  cost: 0.5365380048751831  accuracy: 0.7025998830795288\n",
      "Epoch 46, CIFAR-10 Batch 3:  cost: 0.38596150279045105  accuracy: 0.7083998918533325\n",
      "Epoch 46, CIFAR-10 Batch 4:  cost: 0.4434398412704468  accuracy: 0.6983999013900757\n",
      "Epoch 46, CIFAR-10 Batch 5:  cost: 0.5239994525909424  accuracy: 0.7027997970581055\n",
      "Epoch 47, CIFAR-10 Batch 1:  cost: 0.5364105701446533  accuracy: 0.707399845123291\n",
      "Epoch 47, CIFAR-10 Batch 2:  cost: 0.5853309035301208  accuracy: 0.7047998309135437\n",
      "Epoch 47, CIFAR-10 Batch 3:  cost: 0.42565983533859253  accuracy: 0.7039998173713684\n",
      "Epoch 47, CIFAR-10 Batch 4:  cost: 0.4475291967391968  accuracy: 0.697399914264679\n",
      "Epoch 47, CIFAR-10 Batch 5:  cost: 0.5805761814117432  accuracy: 0.6949998736381531\n",
      "Epoch 48, CIFAR-10 Batch 1:  cost: 0.5599331259727478  accuracy: 0.6977998614311218\n",
      "Epoch 48, CIFAR-10 Batch 2:  cost: 0.5467877388000488  accuracy: 0.7051998376846313\n",
      "Epoch 48, CIFAR-10 Batch 3:  cost: 0.3538781404495239  accuracy: 0.700999915599823\n",
      "Epoch 48, CIFAR-10 Batch 4:  cost: 0.4320143759250641  accuracy: 0.7035998702049255\n",
      "Epoch 48, CIFAR-10 Batch 5:  cost: 0.4839130938053131  accuracy: 0.7031998634338379\n",
      "Epoch 49, CIFAR-10 Batch 1:  cost: 0.5013617277145386  accuracy: 0.7111998796463013\n",
      "Epoch 49, CIFAR-10 Batch 2:  cost: 0.5202125310897827  accuracy: 0.6973998546600342\n",
      "Epoch 49, CIFAR-10 Batch 3:  cost: 0.35177046060562134  accuracy: 0.7051998376846313\n",
      "Epoch 49, CIFAR-10 Batch 4:  cost: 0.4202660322189331  accuracy: 0.7177998423576355\n",
      "Epoch 49, CIFAR-10 Batch 5:  cost: 0.504913330078125  accuracy: 0.7189998626708984\n",
      "Epoch 50, CIFAR-10 Batch 1:  cost: 0.5019165873527527  accuracy: 0.703799843788147\n",
      "Epoch 50, CIFAR-10 Batch 2:  cost: 0.526141881942749  accuracy: 0.7087998390197754\n",
      "Epoch 50, CIFAR-10 Batch 3:  cost: 0.3892771601676941  accuracy: 0.715599775314331\n",
      "Epoch 50, CIFAR-10 Batch 4:  cost: 0.48993632197380066  accuracy: 0.7113998532295227\n",
      "Epoch 50, CIFAR-10 Batch 5:  cost: 0.5030156373977661  accuracy: 0.7081998586654663\n",
      "Epoch 51, CIFAR-10 Batch 1:  cost: 0.4679226577281952  accuracy: 0.7079998254776001\n",
      "Epoch 51, CIFAR-10 Batch 2:  cost: 0.5304813385009766  accuracy: 0.7003999352455139\n",
      "Epoch 51, CIFAR-10 Batch 3:  cost: 0.40721967816352844  accuracy: 0.7061998248100281\n",
      "Epoch 51, CIFAR-10 Batch 4:  cost: 0.4136102497577667  accuracy: 0.7111998796463013\n",
      "Epoch 51, CIFAR-10 Batch 5:  cost: 0.5062459707260132  accuracy: 0.7027998566627502\n",
      "Epoch 52, CIFAR-10 Batch 1:  cost: 0.48341888189315796  accuracy: 0.7115998268127441\n",
      "Epoch 52, CIFAR-10 Batch 2:  cost: 0.5227574706077576  accuracy: 0.6985998749732971\n",
      "Epoch 52, CIFAR-10 Batch 3:  cost: 0.3414955735206604  accuracy: 0.7089998722076416\n",
      "Epoch 52, CIFAR-10 Batch 4:  cost: 0.47802430391311646  accuracy: 0.7147998809814453\n",
      "Epoch 52, CIFAR-10 Batch 5:  cost: 0.47510993480682373  accuracy: 0.709199845790863\n",
      "Epoch 53, CIFAR-10 Batch 1:  cost: 0.5362000465393066  accuracy: 0.7097998857498169\n",
      "Epoch 53, CIFAR-10 Batch 2:  cost: 0.4726996421813965  accuracy: 0.715199887752533\n",
      "Epoch 53, CIFAR-10 Batch 3:  cost: 0.39322608709335327  accuracy: 0.7059998512268066\n",
      "Epoch 53, CIFAR-10 Batch 4:  cost: 0.38474518060684204  accuracy: 0.710399866104126\n",
      "Epoch 53, CIFAR-10 Batch 5:  cost: 0.603538990020752  accuracy: 0.680199921131134\n",
      "Epoch 54, CIFAR-10 Batch 1:  cost: 0.46436989307403564  accuracy: 0.7127998471260071\n",
      "Epoch 54, CIFAR-10 Batch 2:  cost: 0.46816372871398926  accuracy: 0.7135998606681824\n",
      "Epoch 54, CIFAR-10 Batch 3:  cost: 0.353013277053833  accuracy: 0.7125998735427856\n",
      "Epoch 54, CIFAR-10 Batch 4:  cost: 0.43324053287506104  accuracy: 0.7101998329162598\n",
      "Epoch 54, CIFAR-10 Batch 5:  cost: 0.5139721035957336  accuracy: 0.7067998647689819\n",
      "Epoch 55, CIFAR-10 Batch 1:  cost: 0.4593799114227295  accuracy: 0.7167998552322388\n",
      "Epoch 55, CIFAR-10 Batch 2:  cost: 0.4258784353733063  accuracy: 0.7087998390197754\n",
      "Epoch 55, CIFAR-10 Batch 3:  cost: 0.35059958696365356  accuracy: 0.7147998213768005\n",
      "Epoch 55, CIFAR-10 Batch 4:  cost: 0.4186013638973236  accuracy: 0.7101998329162598\n",
      "Epoch 55, CIFAR-10 Batch 5:  cost: 0.466854453086853  accuracy: 0.7127998471260071\n",
      "Epoch 56, CIFAR-10 Batch 1:  cost: 0.435990571975708  accuracy: 0.7089998722076416\n",
      "Epoch 56, CIFAR-10 Batch 2:  cost: 0.45014339685440063  accuracy: 0.7133998274803162\n",
      "Epoch 56, CIFAR-10 Batch 3:  cost: 0.3083131015300751  accuracy: 0.7149998545646667\n",
      "Epoch 56, CIFAR-10 Batch 4:  cost: 0.4398874342441559  accuracy: 0.7207998037338257\n",
      "Epoch 56, CIFAR-10 Batch 5:  cost: 0.5062034726142883  accuracy: 0.7109999060630798\n",
      "Epoch 57, CIFAR-10 Batch 1:  cost: 0.48766815662384033  accuracy: 0.709199845790863\n",
      "Epoch 57, CIFAR-10 Batch 2:  cost: 0.48747509717941284  accuracy: 0.703799843788147\n",
      "Epoch 57, CIFAR-10 Batch 3:  cost: 0.3557435870170593  accuracy: 0.7081998586654663\n",
      "Epoch 57, CIFAR-10 Batch 4:  cost: 0.45189788937568665  accuracy: 0.7071998715400696\n",
      "Epoch 57, CIFAR-10 Batch 5:  cost: 0.4819834232330322  accuracy: 0.7225998044013977\n",
      "Epoch 58, CIFAR-10 Batch 1:  cost: 0.4639672040939331  accuracy: 0.7201998829841614\n",
      "Epoch 58, CIFAR-10 Batch 2:  cost: 0.4994582533836365  accuracy: 0.7057998776435852\n",
      "Epoch 58, CIFAR-10 Batch 3:  cost: 0.3203507661819458  accuracy: 0.7117998600006104\n",
      "Epoch 58, CIFAR-10 Batch 4:  cost: 0.40882307291030884  accuracy: 0.715199887752533\n",
      "Epoch 58, CIFAR-10 Batch 5:  cost: 0.4321863651275635  accuracy: 0.7087998986244202\n",
      "Epoch 59, CIFAR-10 Batch 1:  cost: 0.4857232868671417  accuracy: 0.7143998146057129\n",
      "Epoch 59, CIFAR-10 Batch 2:  cost: 0.43282419443130493  accuracy: 0.7117999196052551\n",
      "Epoch 59, CIFAR-10 Batch 3:  cost: 0.3435947895050049  accuracy: 0.7183997631072998\n",
      "Epoch 59, CIFAR-10 Batch 4:  cost: 0.45662248134613037  accuracy: 0.7113999128341675\n",
      "Epoch 59, CIFAR-10 Batch 5:  cost: 0.4941040277481079  accuracy: 0.7075998187065125\n",
      "Epoch 60, CIFAR-10 Batch 1:  cost: 0.5083067417144775  accuracy: 0.7109998464584351\n",
      "Epoch 60, CIFAR-10 Batch 2:  cost: 0.4521767497062683  accuracy: 0.7081998586654663\n",
      "Epoch 60, CIFAR-10 Batch 3:  cost: 0.33859002590179443  accuracy: 0.7179998159408569\n",
      "Epoch 60, CIFAR-10 Batch 4:  cost: 0.38485193252563477  accuracy: 0.719799816608429\n",
      "Epoch 60, CIFAR-10 Batch 5:  cost: 0.4224867820739746  accuracy: 0.7175998687744141\n",
      "Epoch 61, CIFAR-10 Batch 1:  cost: 0.44919446110725403  accuracy: 0.7119998931884766\n",
      "Epoch 61, CIFAR-10 Batch 2:  cost: 0.46461495757102966  accuracy: 0.7147998213768005\n",
      "Epoch 61, CIFAR-10 Batch 3:  cost: 0.3299597203731537  accuracy: 0.7093998789787292\n",
      "Epoch 61, CIFAR-10 Batch 4:  cost: 0.3768368661403656  accuracy: 0.7161998748779297\n",
      "Epoch 61, CIFAR-10 Batch 5:  cost: 0.39618775248527527  accuracy: 0.7109998464584351\n",
      "Epoch 62, CIFAR-10 Batch 1:  cost: 0.4550968408584595  accuracy: 0.7133998870849609\n",
      "Epoch 62, CIFAR-10 Batch 2:  cost: 0.46004366874694824  accuracy: 0.7159998416900635\n",
      "Epoch 62, CIFAR-10 Batch 3:  cost: 0.3159096837043762  accuracy: 0.7225998640060425\n",
      "Epoch 62, CIFAR-10 Batch 4:  cost: 0.4527641832828522  accuracy: 0.704399824142456\n",
      "Epoch 62, CIFAR-10 Batch 5:  cost: 0.41132938861846924  accuracy: 0.7111998200416565\n",
      "Epoch 63, CIFAR-10 Batch 1:  cost: 0.4298306703567505  accuracy: 0.7193998694419861\n",
      "Epoch 63, CIFAR-10 Batch 2:  cost: 0.429414838552475  accuracy: 0.7205998301506042\n",
      "Epoch 63, CIFAR-10 Batch 3:  cost: 0.3255249559879303  accuracy: 0.715199887752533\n",
      "Epoch 63, CIFAR-10 Batch 4:  cost: 0.3756956458091736  accuracy: 0.7205998301506042\n",
      "Epoch 63, CIFAR-10 Batch 5:  cost: 0.43226781487464905  accuracy: 0.7151998281478882\n",
      "Epoch 64, CIFAR-10 Batch 1:  cost: 0.4443734884262085  accuracy: 0.7249998450279236\n",
      "Epoch 64, CIFAR-10 Batch 2:  cost: 0.4372886121273041  accuracy: 0.710399866104126\n",
      "Epoch 64, CIFAR-10 Batch 3:  cost: 0.3506854772567749  accuracy: 0.7167998552322388\n",
      "Epoch 64, CIFAR-10 Batch 4:  cost: 0.4187485873699188  accuracy: 0.7113997936248779\n",
      "Epoch 64, CIFAR-10 Batch 5:  cost: 0.4135928153991699  accuracy: 0.7151998281478882\n",
      "Epoch 65, CIFAR-10 Batch 1:  cost: 0.44125351309776306  accuracy: 0.7265998721122742\n",
      "Epoch 65, CIFAR-10 Batch 2:  cost: 0.46140265464782715  accuracy: 0.7147998809814453\n",
      "Epoch 65, CIFAR-10 Batch 3:  cost: 0.3241671025753021  accuracy: 0.7197998762130737\n",
      "Epoch 65, CIFAR-10 Batch 4:  cost: 0.38989096879959106  accuracy: 0.7193998098373413\n",
      "Epoch 65, CIFAR-10 Batch 5:  cost: 0.3913496434688568  accuracy: 0.7253998517990112\n",
      "Epoch 66, CIFAR-10 Batch 1:  cost: 0.4415992200374603  accuracy: 0.7235997915267944\n",
      "Epoch 66, CIFAR-10 Batch 2:  cost: 0.47285139560699463  accuracy: 0.7083998918533325\n",
      "Epoch 66, CIFAR-10 Batch 3:  cost: 0.31530192494392395  accuracy: 0.7093998789787292\n",
      "Epoch 66, CIFAR-10 Batch 4:  cost: 0.3959525227546692  accuracy: 0.7151998281478882\n",
      "Epoch 66, CIFAR-10 Batch 5:  cost: 0.4115775227546692  accuracy: 0.7081998586654663\n",
      "Epoch 67, CIFAR-10 Batch 1:  cost: 0.43844181299209595  accuracy: 0.7185998558998108\n",
      "Epoch 67, CIFAR-10 Batch 2:  cost: 0.45324820280075073  accuracy: 0.7205998301506042\n",
      "Epoch 67, CIFAR-10 Batch 3:  cost: 0.34470057487487793  accuracy: 0.7199998497962952\n",
      "Epoch 67, CIFAR-10 Batch 4:  cost: 0.4208090007305145  accuracy: 0.7191998362541199\n",
      "Epoch 67, CIFAR-10 Batch 5:  cost: 0.3888024091720581  accuracy: 0.7143998146057129\n",
      "Epoch 68, CIFAR-10 Batch 1:  cost: 0.4495895802974701  accuracy: 0.7177998423576355\n",
      "Epoch 68, CIFAR-10 Batch 2:  cost: 0.4605700671672821  accuracy: 0.7133998274803162\n",
      "Epoch 68, CIFAR-10 Batch 3:  cost: 0.30813729763031006  accuracy: 0.7127997875213623\n",
      "Epoch 68, CIFAR-10 Batch 4:  cost: 0.3618459701538086  accuracy: 0.7179998755455017\n",
      "Epoch 68, CIFAR-10 Batch 5:  cost: 0.42056480050086975  accuracy: 0.7141997814178467\n",
      "Epoch 69, CIFAR-10 Batch 1:  cost: 0.4090301990509033  accuracy: 0.7221998572349548\n",
      "Epoch 69, CIFAR-10 Batch 2:  cost: 0.46621501445770264  accuracy: 0.719799816608429\n",
      "Epoch 69, CIFAR-10 Batch 3:  cost: 0.31889238953590393  accuracy: 0.7203998565673828\n",
      "Epoch 69, CIFAR-10 Batch 4:  cost: 0.34926900267601013  accuracy: 0.7199999094009399\n",
      "Epoch 69, CIFAR-10 Batch 5:  cost: 0.40782630443573  accuracy: 0.7155998349189758\n",
      "Epoch 70, CIFAR-10 Batch 1:  cost: 0.4463973343372345  accuracy: 0.7257998585700989\n",
      "Epoch 70, CIFAR-10 Batch 2:  cost: 0.4128953814506531  accuracy: 0.7109998464584351\n",
      "Epoch 70, CIFAR-10 Batch 3:  cost: 0.3234201669692993  accuracy: 0.7171998023986816\n",
      "Epoch 70, CIFAR-10 Batch 4:  cost: 0.3377583920955658  accuracy: 0.726399838924408\n",
      "Epoch 70, CIFAR-10 Batch 5:  cost: 0.39042115211486816  accuracy: 0.7143998146057129\n",
      "Epoch 71, CIFAR-10 Batch 1:  cost: 0.4228796362876892  accuracy: 0.7227998971939087\n",
      "Epoch 71, CIFAR-10 Batch 2:  cost: 0.4159244894981384  accuracy: 0.7151998281478882\n",
      "Epoch 71, CIFAR-10 Batch 3:  cost: 0.30798548460006714  accuracy: 0.7183998823165894\n",
      "Epoch 71, CIFAR-10 Batch 4:  cost: 0.37885522842407227  accuracy: 0.7161998152732849\n",
      "Epoch 71, CIFAR-10 Batch 5:  cost: 0.3994574546813965  accuracy: 0.7129998803138733\n",
      "Epoch 72, CIFAR-10 Batch 1:  cost: 0.4341672956943512  accuracy: 0.7205998301506042\n",
      "Epoch 72, CIFAR-10 Batch 2:  cost: 0.42503732442855835  accuracy: 0.7163998484611511\n",
      "Epoch 72, CIFAR-10 Batch 3:  cost: 0.30268558859825134  accuracy: 0.7219998240470886\n",
      "Epoch 72, CIFAR-10 Batch 4:  cost: 0.3788999319076538  accuracy: 0.7137998342514038\n",
      "Epoch 72, CIFAR-10 Batch 5:  cost: 0.3688579797744751  accuracy: 0.7225998640060425\n",
      "Epoch 73, CIFAR-10 Batch 1:  cost: 0.4628719389438629  accuracy: 0.7115998268127441\n",
      "Epoch 73, CIFAR-10 Batch 2:  cost: 0.4099150002002716  accuracy: 0.7203998565673828\n",
      "Epoch 73, CIFAR-10 Batch 3:  cost: 0.2876184582710266  accuracy: 0.7199999094009399\n",
      "Epoch 73, CIFAR-10 Batch 4:  cost: 0.3721197843551636  accuracy: 0.723399817943573\n",
      "Epoch 73, CIFAR-10 Batch 5:  cost: 0.3956196904182434  accuracy: 0.7147998809814453\n",
      "Epoch 74, CIFAR-10 Batch 1:  cost: 0.42220836877822876  accuracy: 0.7195998430252075\n",
      "Epoch 74, CIFAR-10 Batch 2:  cost: 0.3821801245212555  accuracy: 0.7201998829841614\n",
      "Epoch 74, CIFAR-10 Batch 3:  cost: 0.293580025434494  accuracy: 0.723399817943573\n",
      "Epoch 74, CIFAR-10 Batch 4:  cost: 0.3440113365650177  accuracy: 0.7189998626708984\n",
      "Epoch 74, CIFAR-10 Batch 5:  cost: 0.3714359998703003  accuracy: 0.7117998003959656\n",
      "Epoch 75, CIFAR-10 Batch 1:  cost: 0.4100489318370819  accuracy: 0.7227997779846191\n",
      "Epoch 75, CIFAR-10 Batch 2:  cost: 0.4084646701812744  accuracy: 0.7219998836517334\n",
      "Epoch 75, CIFAR-10 Batch 3:  cost: 0.2943260669708252  accuracy: 0.723599910736084\n",
      "Epoch 75, CIFAR-10 Batch 4:  cost: 0.3263176381587982  accuracy: 0.7233998775482178\n",
      "Epoch 75, CIFAR-10 Batch 5:  cost: 0.44443273544311523  accuracy: 0.714999794960022\n",
      "Epoch 76, CIFAR-10 Batch 1:  cost: 0.3804076611995697  accuracy: 0.7285998463630676\n",
      "Epoch 76, CIFAR-10 Batch 2:  cost: 0.42598336935043335  accuracy: 0.7177998423576355\n",
      "Epoch 76, CIFAR-10 Batch 3:  cost: 0.2727397680282593  accuracy: 0.7213998436927795\n",
      "Epoch 76, CIFAR-10 Batch 4:  cost: 0.3424225151538849  accuracy: 0.7271997928619385\n",
      "Epoch 76, CIFAR-10 Batch 5:  cost: 0.4246859550476074  accuracy: 0.720399796962738\n",
      "Epoch 77, CIFAR-10 Batch 1:  cost: 0.4534236788749695  accuracy: 0.7091999053955078\n",
      "Epoch 77, CIFAR-10 Batch 2:  cost: 0.39038097858428955  accuracy: 0.7273998856544495\n",
      "Epoch 77, CIFAR-10 Batch 3:  cost: 0.2858414947986603  accuracy: 0.718799889087677\n",
      "Epoch 77, CIFAR-10 Batch 4:  cost: 0.3237934410572052  accuracy: 0.7275998592376709\n",
      "Epoch 77, CIFAR-10 Batch 5:  cost: 0.35654640197753906  accuracy: 0.7243998050689697\n",
      "Epoch 78, CIFAR-10 Batch 1:  cost: 0.44914233684539795  accuracy: 0.726399838924408\n",
      "Epoch 78, CIFAR-10 Batch 2:  cost: 0.3926888108253479  accuracy: 0.7247998118400574\n",
      "Epoch 78, CIFAR-10 Batch 3:  cost: 0.28565093874931335  accuracy: 0.7131999135017395\n",
      "Epoch 78, CIFAR-10 Batch 4:  cost: 0.3739091157913208  accuracy: 0.7205998301506042\n",
      "Epoch 78, CIFAR-10 Batch 5:  cost: 0.42445820569992065  accuracy: 0.7147998809814453\n",
      "Epoch 79, CIFAR-10 Batch 1:  cost: 0.4354832172393799  accuracy: 0.7255998849868774\n",
      "Epoch 79, CIFAR-10 Batch 2:  cost: 0.4034635126590729  accuracy: 0.7181998491287231\n",
      "Epoch 79, CIFAR-10 Batch 3:  cost: 0.33193254470825195  accuracy: 0.7219998836517334\n",
      "Epoch 79, CIFAR-10 Batch 4:  cost: 0.33696502447128296  accuracy: 0.7143998146057129\n",
      "Epoch 79, CIFAR-10 Batch 5:  cost: 0.39204221963882446  accuracy: 0.7127998471260071\n",
      "Epoch 80, CIFAR-10 Batch 1:  cost: 0.44771823287010193  accuracy: 0.7259998917579651\n",
      "Epoch 80, CIFAR-10 Batch 2:  cost: 0.38784652948379517  accuracy: 0.7249997854232788\n",
      "Epoch 80, CIFAR-10 Batch 3:  cost: 0.2890813946723938  accuracy: 0.7191998958587646\n",
      "Epoch 80, CIFAR-10 Batch 4:  cost: 0.35083502531051636  accuracy: 0.7199997901916504\n",
      "Epoch 80, CIFAR-10 Batch 5:  cost: 0.3990786671638489  accuracy: 0.7105998992919922\n",
      "Epoch 81, CIFAR-10 Batch 1:  cost: 0.3972635865211487  accuracy: 0.7239997982978821\n",
      "Epoch 81, CIFAR-10 Batch 2:  cost: 0.4245232343673706  accuracy: 0.7201998233795166\n",
      "Epoch 81, CIFAR-10 Batch 3:  cost: 0.2811974883079529  accuracy: 0.7249998450279236\n",
      "Epoch 81, CIFAR-10 Batch 4:  cost: 0.33404457569122314  accuracy: 0.7161998748779297\n",
      "Epoch 81, CIFAR-10 Batch 5:  cost: 0.3823481798171997  accuracy: 0.7039998173713684\n",
      "Epoch 82, CIFAR-10 Batch 1:  cost: 0.4300002455711365  accuracy: 0.7209998965263367\n",
      "Epoch 82, CIFAR-10 Batch 2:  cost: 0.4144972562789917  accuracy: 0.7209998369216919\n",
      "Epoch 82, CIFAR-10 Batch 3:  cost: 0.29997217655181885  accuracy: 0.7175998687744141\n",
      "Epoch 82, CIFAR-10 Batch 4:  cost: 0.3220374882221222  accuracy: 0.7259998917579651\n",
      "Epoch 82, CIFAR-10 Batch 5:  cost: 0.3765004277229309  accuracy: 0.7195998430252075\n",
      "Epoch 83, CIFAR-10 Batch 1:  cost: 0.423355370759964  accuracy: 0.7217998504638672\n",
      "Epoch 83, CIFAR-10 Batch 2:  cost: 0.39163830876350403  accuracy: 0.7191998958587646\n",
      "Epoch 83, CIFAR-10 Batch 3:  cost: 0.27749207615852356  accuracy: 0.7215998768806458\n",
      "Epoch 83, CIFAR-10 Batch 4:  cost: 0.3547963798046112  accuracy: 0.720399796962738\n",
      "Epoch 83, CIFAR-10 Batch 5:  cost: 0.3737757205963135  accuracy: 0.7131998538970947\n",
      "Epoch 84, CIFAR-10 Batch 1:  cost: 0.4451161026954651  accuracy: 0.7227997779846191\n",
      "Epoch 84, CIFAR-10 Batch 2:  cost: 0.39899909496307373  accuracy: 0.720399796962738\n",
      "Epoch 84, CIFAR-10 Batch 3:  cost: 0.28613030910491943  accuracy: 0.7221998572349548\n",
      "Epoch 84, CIFAR-10 Batch 4:  cost: 0.3299436867237091  accuracy: 0.7159998416900635\n",
      "Epoch 84, CIFAR-10 Batch 5:  cost: 0.33169877529144287  accuracy: 0.7209998369216919\n",
      "Epoch 85, CIFAR-10 Batch 1:  cost: 0.3951694965362549  accuracy: 0.7321998476982117\n",
      "Epoch 85, CIFAR-10 Batch 2:  cost: 0.4065471887588501  accuracy: 0.7243998646736145\n",
      "Epoch 85, CIFAR-10 Batch 3:  cost: 0.2632009983062744  accuracy: 0.7265998721122742\n",
      "Epoch 85, CIFAR-10 Batch 4:  cost: 0.33046025037765503  accuracy: 0.7209998369216919\n",
      "Epoch 85, CIFAR-10 Batch 5:  cost: 0.3714735507965088  accuracy: 0.7225998640060425\n",
      "Epoch 86, CIFAR-10 Batch 1:  cost: 0.3939644694328308  accuracy: 0.7263998985290527\n",
      "Epoch 86, CIFAR-10 Batch 2:  cost: 0.3969665765762329  accuracy: 0.7247998714447021\n",
      "Epoch 86, CIFAR-10 Batch 3:  cost: 0.26800376176834106  accuracy: 0.7237998247146606\n",
      "Epoch 86, CIFAR-10 Batch 4:  cost: 0.38015538454055786  accuracy: 0.7225998640060425\n",
      "Epoch 86, CIFAR-10 Batch 5:  cost: 0.34096837043762207  accuracy: 0.7173998951911926\n",
      "Epoch 87, CIFAR-10 Batch 1:  cost: 0.41775602102279663  accuracy: 0.7295998334884644\n",
      "Epoch 87, CIFAR-10 Batch 2:  cost: 0.4014260470867157  accuracy: 0.7273997664451599\n",
      "Epoch 87, CIFAR-10 Batch 3:  cost: 0.26458901166915894  accuracy: 0.7245998978614807\n",
      "Epoch 87, CIFAR-10 Batch 4:  cost: 0.34239351749420166  accuracy: 0.7255997657775879\n",
      "Epoch 87, CIFAR-10 Batch 5:  cost: 0.358235239982605  accuracy: 0.7085999250411987\n",
      "Epoch 88, CIFAR-10 Batch 1:  cost: 0.4037284255027771  accuracy: 0.7291997671127319\n",
      "Epoch 88, CIFAR-10 Batch 2:  cost: 0.39885982871055603  accuracy: 0.7259998321533203\n",
      "Epoch 88, CIFAR-10 Batch 3:  cost: 0.27567484974861145  accuracy: 0.7191998362541199\n",
      "Epoch 88, CIFAR-10 Batch 4:  cost: 0.3420664072036743  accuracy: 0.7179998159408569\n",
      "Epoch 88, CIFAR-10 Batch 5:  cost: 0.3438243865966797  accuracy: 0.7089998722076416\n",
      "Epoch 89, CIFAR-10 Batch 1:  cost: 0.4034803509712219  accuracy: 0.7257997989654541\n",
      "Epoch 89, CIFAR-10 Batch 2:  cost: 0.4053479731082916  accuracy: 0.7233998775482178\n",
      "Epoch 89, CIFAR-10 Batch 3:  cost: 0.27718424797058105  accuracy: 0.7239997982978821\n",
      "Epoch 89, CIFAR-10 Batch 4:  cost: 0.2985588014125824  accuracy: 0.7279998660087585\n",
      "Epoch 89, CIFAR-10 Batch 5:  cost: 0.3274754285812378  accuracy: 0.7241998910903931\n",
      "Epoch 90, CIFAR-10 Batch 1:  cost: 0.392929345369339  accuracy: 0.7201998233795166\n",
      "Epoch 90, CIFAR-10 Batch 2:  cost: 0.40429598093032837  accuracy: 0.7233998775482178\n",
      "Epoch 90, CIFAR-10 Batch 3:  cost: 0.26118001341819763  accuracy: 0.7305998206138611\n",
      "Epoch 90, CIFAR-10 Batch 4:  cost: 0.3392999768257141  accuracy: 0.7303999066352844\n",
      "Epoch 90, CIFAR-10 Batch 5:  cost: 0.38144221901893616  accuracy: 0.7127999067306519\n",
      "Epoch 91, CIFAR-10 Batch 1:  cost: 0.3919118642807007  accuracy: 0.7305997610092163\n",
      "Epoch 91, CIFAR-10 Batch 2:  cost: 0.38572007417678833  accuracy: 0.7313998341560364\n",
      "Epoch 91, CIFAR-10 Batch 3:  cost: 0.23696976900100708  accuracy: 0.7277998328208923\n",
      "Epoch 91, CIFAR-10 Batch 4:  cost: 0.32117757201194763  accuracy: 0.72819983959198\n",
      "Epoch 91, CIFAR-10 Batch 5:  cost: 0.3812127113342285  accuracy: 0.7195998430252075\n",
      "Epoch 92, CIFAR-10 Batch 1:  cost: 0.34845787286758423  accuracy: 0.730199933052063\n",
      "Epoch 92, CIFAR-10 Batch 2:  cost: 0.41785117983818054  accuracy: 0.72819983959198\n",
      "Epoch 92, CIFAR-10 Batch 3:  cost: 0.2752678096294403  accuracy: 0.7207999229431152\n",
      "Epoch 92, CIFAR-10 Batch 4:  cost: 0.2939132750034332  accuracy: 0.7265998125076294\n",
      "Epoch 92, CIFAR-10 Batch 5:  cost: 0.35769370198249817  accuracy: 0.7237998247146606\n",
      "Epoch 93, CIFAR-10 Batch 1:  cost: 0.34683650732040405  accuracy: 0.7321999073028564\n",
      "Epoch 93, CIFAR-10 Batch 2:  cost: 0.4004160761833191  accuracy: 0.7243998646736145\n",
      "Epoch 93, CIFAR-10 Batch 3:  cost: 0.2744116485118866  accuracy: 0.7327998280525208\n",
      "Epoch 93, CIFAR-10 Batch 4:  cost: 0.3016895055770874  accuracy: 0.7283998131752014\n",
      "Epoch 93, CIFAR-10 Batch 5:  cost: 0.3156677484512329  accuracy: 0.7231998443603516\n",
      "Epoch 94, CIFAR-10 Batch 1:  cost: 0.39423197507858276  accuracy: 0.72819983959198\n",
      "Epoch 94, CIFAR-10 Batch 2:  cost: 0.4007301330566406  accuracy: 0.7253998517990112\n",
      "Epoch 94, CIFAR-10 Batch 3:  cost: 0.281802773475647  accuracy: 0.7293999195098877\n",
      "Epoch 94, CIFAR-10 Batch 4:  cost: 0.3311781883239746  accuracy: 0.7133998274803162\n",
      "Epoch 94, CIFAR-10 Batch 5:  cost: 0.322098970413208  accuracy: 0.7237998843193054\n",
      "Epoch 95, CIFAR-10 Batch 1:  cost: 0.38510408997535706  accuracy: 0.7237998843193054\n",
      "Epoch 95, CIFAR-10 Batch 2:  cost: 0.41510671377182007  accuracy: 0.7183998823165894\n",
      "Epoch 95, CIFAR-10 Batch 3:  cost: 0.27186107635498047  accuracy: 0.7155998349189758\n",
      "Epoch 95, CIFAR-10 Batch 4:  cost: 0.31530505418777466  accuracy: 0.7175998687744141\n",
      "Epoch 95, CIFAR-10 Batch 5:  cost: 0.3323996663093567  accuracy: 0.7153998613357544\n",
      "Epoch 96, CIFAR-10 Batch 1:  cost: 0.38474833965301514  accuracy: 0.7253998517990112\n",
      "Epoch 96, CIFAR-10 Batch 2:  cost: 0.417949914932251  accuracy: 0.7191998958587646\n",
      "Epoch 96, CIFAR-10 Batch 3:  cost: 0.24670493602752686  accuracy: 0.7261998653411865\n",
      "Epoch 96, CIFAR-10 Batch 4:  cost: 0.3003864288330078  accuracy: 0.7275998592376709\n",
      "Epoch 96, CIFAR-10 Batch 5:  cost: 0.3344748616218567  accuracy: 0.7241998314857483\n",
      "Epoch 97, CIFAR-10 Batch 1:  cost: 0.41741910576820374  accuracy: 0.7219998240470886\n",
      "Epoch 97, CIFAR-10 Batch 2:  cost: 0.39514610171318054  accuracy: 0.7283998131752014\n",
      "Epoch 97, CIFAR-10 Batch 3:  cost: 0.2843707203865051  accuracy: 0.7189998626708984\n",
      "Epoch 97, CIFAR-10 Batch 4:  cost: 0.31890279054641724  accuracy: 0.7273998260498047\n",
      "Epoch 97, CIFAR-10 Batch 5:  cost: 0.32359570264816284  accuracy: 0.7243998646736145\n",
      "Epoch 98, CIFAR-10 Batch 1:  cost: 0.35175788402557373  accuracy: 0.7305998802185059\n",
      "Epoch 98, CIFAR-10 Batch 2:  cost: 0.4060728847980499  accuracy: 0.7279998064041138\n",
      "Epoch 98, CIFAR-10 Batch 3:  cost: 0.28622573614120483  accuracy: 0.7259997725486755\n",
      "Epoch 98, CIFAR-10 Batch 4:  cost: 0.2824177145957947  accuracy: 0.7283998131752014\n",
      "Epoch 98, CIFAR-10 Batch 5:  cost: 0.3199514150619507  accuracy: 0.7275998592376709\n",
      "Epoch 99, CIFAR-10 Batch 1:  cost: 0.3532533645629883  accuracy: 0.7287998199462891\n",
      "Epoch 99, CIFAR-10 Batch 2:  cost: 0.38235220313072205  accuracy: 0.715799868106842\n",
      "Epoch 99, CIFAR-10 Batch 3:  cost: 0.260724276304245  accuracy: 0.7223998308181763\n",
      "Epoch 99, CIFAR-10 Batch 4:  cost: 0.3199011981487274  accuracy: 0.7201998233795166\n",
      "Epoch 99, CIFAR-10 Batch 5:  cost: 0.2940969467163086  accuracy: 0.7325997948646545\n",
      "Epoch 100, CIFAR-10 Batch 1:  cost: 0.3688599765300751  accuracy: 0.723599910736084\n",
      "Epoch 100, CIFAR-10 Batch 2:  cost: 0.3732666075229645  accuracy: 0.72819983959198\n",
      "Epoch 100, CIFAR-10 Batch 3:  cost: 0.2534259557723999  accuracy: 0.7243998646736145\n",
      "Epoch 100, CIFAR-10 Batch 4:  cost: 0.29387107491493225  accuracy: 0.7309998869895935\n",
      "Epoch 100, CIFAR-10 Batch 5:  cost: 0.324122816324234  accuracy: 0.7219999432563782\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.7164754746835443\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nov8PlBrOxqSBrXAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11a09442e8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_test.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for test_feature_batch, test_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: test_feature_batch, loaded_y: test_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-80% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
